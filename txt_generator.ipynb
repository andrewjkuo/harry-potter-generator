{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pickle import dump, load\n",
    "from random import randint\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, LSTM, Embedding\n",
    "\n",
    "from txt2sequence import convert_to_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Text to Sequences\n",
    "N.B. If 'texts/hp_sequences.txt' has already been generated you don't need to run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert_to_sequences()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/251019/model.json', 'r') as json_file:\n",
    "    json_model = json_file.read()\n",
    "\n",
    "model = model_from_json(json_model)\n",
    "model.load_weights('models/251019/model.h5')\n",
    "\n",
    "\n",
    "tokenizer = load(open('models/251019/tokenizer.pkl', 'rb'))\n",
    "reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))\n",
    "unk_ind = tokenizer.word_index['unknownword']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, 'r')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text\n",
    " \n",
    "# load cleaned text sequences\n",
    "in_filename = 'texts/hp_sequences.txt'\n",
    "doc = load_doc(in_filename)\n",
    "lines = doc.split('\\n')\n",
    "seq_length = len(lines[0].split()) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions\n",
    "def capitalise(sentence):\n",
    "    return sentence[0].upper() + sentence[1:]\n",
    "\n",
    "def sentence_case(text, punct):\n",
    "    punct = punct + ' '\n",
    "    text = map(capitalise, [x for x in text.split(punct)])\n",
    "    return punct.join(text)\n",
    "\n",
    "def display_txt(text):\n",
    "    first_stop = False\n",
    "    if text[:13] == 'endofsentence':\n",
    "        text = text[13:]\n",
    "        first_stop = True\n",
    "    text = text.replace(' endofsentence ', '. ')\n",
    "    text = text.replace('endofsentence','')\n",
    "    text = sentence_case(text, '.')\n",
    "    text = sentence_case(text, '?')\n",
    "    text = sentence_case(text, '!')\n",
    "    if first_stop:\n",
    "        text = '. ' + text\n",
    "    print(text)\n",
    "    \n",
    "def prepare_txt(text):\n",
    "    text = text.replace('. ', ' endofsentence ')\n",
    "    text = text.lower()\n",
    "    text = ' '.join([word if word in tokenizer.word_index.keys() else 'unknownword' for word in text.split(' ')])\n",
    "    return text\n",
    "\n",
    "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
    "    result = list()\n",
    "    in_text = seed_text\n",
    "    # generate a fixed number of words\n",
    "    for _ in range(n_words):\n",
    "        # encode the text as integer\n",
    "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        # truncate sequences to a fixed length\n",
    "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "        # predict probabilities for each word\n",
    "        probs = model.predict_proba(encoded, verbose=0)[0]\n",
    "        \n",
    "        # only consider top n best words\n",
    "        n = 5\n",
    "        inds = [x for x in np.argpartition(probs, -n)[-n:] if x != unk_ind]\n",
    "\n",
    "        probs = probs[inds] / probs[inds].sum()\n",
    "\n",
    "        word_ind = np.random.choice(inds, p=probs)\n",
    "        out_word = reverse_word_map[word_ind]\n",
    "        \n",
    "        in_text += ' ' + out_word\n",
    "        result.append(out_word)\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Said harry his hand shaking. Its all right im here make it stop make it stop moaned dumbledore. Yes. Yes thisll make it stop lied harry. He tipped the contents of the goblet into dumbledores open mouth. Dumbledore screamed the noise echoed all around the vast\n"
     ]
    }
   ],
   "source": [
    "# get random line from the books to use as the seed\n",
    "seed_text = lines[randint(0,len(lines))]\n",
    "display_txt(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Landing in a large sky. Harry ignored him. They ought to have been expelled. And the dursleys had received a few hours of the summer he was sure that his eyes were now asleep as they walked in and out of sight. Ron was still dressed. The next morning harry had to explain how to teach the first week he had had to discuss the summer. They had not seen what was happening. Harry recognized the dursleys. He was not sure it was the first years to destroy it had been the\n"
     ]
    }
   ],
   "source": [
    "generated = generate_seq(model, tokenizer, seq_length, prepare_txt(seed_text), 100)\n",
    "display_txt(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
