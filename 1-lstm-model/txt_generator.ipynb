{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pickle import dump, load\n",
    "from random import randint\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, LSTM, Embedding\n",
    "\n",
    "from txt2sequence import convert_to_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Text to Sequences\n",
    "N.B. If 'texts/hp_sequences.txt' has already been generated you don't need to run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing books\n",
      "cleaning text\n",
      "removing infrequent words\n",
      "saving sequences to file\n"
     ]
    }
   ],
   "source": [
    "convert_to_sequences()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "with open('models/070520/model.json', 'r') as json_file:\n",
    "    json_model = json_file.read()\n",
    "\n",
    "model = model_from_json(json_model)\n",
    "model.load_weights('models/070520/model.h5')\n",
    "\n",
    "\n",
    "tokenizer = load(open('models/070520/tokenizer.pkl', 'rb'))\n",
    "reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))\n",
    "unk_ind = tokenizer.word_index['unknownword']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, 'r')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text\n",
    " \n",
    "# load cleaned text sequences\n",
    "in_filename = 'texts/hp_sequences.txt'\n",
    "doc = load_doc(in_filename)\n",
    "lines = doc.split('\\n')\n",
    "seq_length = len(lines[0].split()) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions\n",
    "def capitalise(sentence):\n",
    "    if len(sentence) != 0:\n",
    "        return sentence[0].upper() + sentence[1:]\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def sentence_case(text, punct):\n",
    "    punct = punct + ' '\n",
    "    text = map(capitalise, [x for x in text.split(punct)])\n",
    "    return punct.join(text)\n",
    "\n",
    "def display_txt(text):\n",
    "    first_stop = False\n",
    "    if text[:13] == 'endofsentence':\n",
    "        text = text[13:]\n",
    "        first_stop = True\n",
    "    text = text.replace(' endofsentence ', '. ')\n",
    "    text = text.replace('endofsentence','')\n",
    "    text = sentence_case(text, '.')\n",
    "    text = sentence_case(text, '?')\n",
    "    text = sentence_case(text, '!')\n",
    "    if first_stop:\n",
    "        text = '. ' + text\n",
    "    print(text)\n",
    "    \n",
    "def prepare_txt(text):\n",
    "    if text[-1] == '.':\n",
    "        text = text[:-1] + ' endofsentence'\n",
    "    text = text.replace('. ', ' endofsentence ')\n",
    "    text = text.lower()\n",
    "    text = ' '.join([word if word in tokenizer.word_index.keys() else 'unknownword' for word in text.split(' ')])\n",
    "    return text\n",
    "\n",
    "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
    "    result = list()\n",
    "    in_text = seed_text\n",
    "    # generate a fixed number of words\n",
    "    for _ in range(n_words):\n",
    "        # encode the text as integer\n",
    "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        # truncate sequences to a fixed length\n",
    "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "        # predict probabilities for each word\n",
    "        probs = model.predict_proba(encoded, verbose=0)[0]\n",
    "        \n",
    "        # only consider top n best words\n",
    "        n = 5\n",
    "        inds = [x for x in np.argpartition(probs, -n)[-n:] if x != unk_ind]\n",
    "\n",
    "        probs = probs[inds] / probs[inds].sum()\n",
    "\n",
    "        word_ind = np.random.choice(inds, p=probs)\n",
    "        out_word = reverse_word_map[word_ind]\n",
    "        \n",
    "        in_text += ' ' + out_word\n",
    "        result.append(out_word)\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate new text it is necessary to provide some input seed text. This can either be done by taking a random line from the original Harry Potter books OR writing your own seed text from scratch. Both techniques are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry ran to the compartment door and ron threw it open and stood back to let him on. They leaned out of the window and waved at mr and mrs weasley until the train turned a corner and blocked them from view. I need to talk to you in\n"
     ]
    }
   ],
   "source": [
    "# get random line from the books to use as the seed\n",
    "seed_text = lines[randint(0,len(lines))]\n",
    "display_txt(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The department of mysteries said harry truthfully. I was going to tell us that he was a good idea of doing it said ron indicating the large bound jug and stalked with her long handkerchief. I dunno said harry. He keeps thinking. Yeah said ron. And i know. I dunno said harry crossly. I think he teaches meself. And thats what happened to you. Said harry hotly. Harry said nothing but he was a great prickling that he was not a growing dark mark in azkaban. He was thinner\n"
     ]
    }
   ],
   "source": [
    "generated = generate_seq(model, tokenizer, seq_length, prepare_txt(seed_text), 100)\n",
    "display_txt(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use custom input as seed text\n",
    "seed_text = \"Sirius Black and Harry were both riding the Hogwarts Express in disguise. There were a number of aurors on board who were none the wiser.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dursleys had only flared in the midst of the corner beside him the moment of witchcraft and faded he had sprung with silver smoke blazing with flaming dark hair and silver glittered pots bottles in the grass. Harry felt his face now strongly that the only sound in his hand swam from nowhere previously. Harry recognized the pain of his hood he felt himself so violently to the ground and his knees that was in azkaban. . .  it belonged. . . . The eyes boy was still glistening\n"
     ]
    }
   ],
   "source": [
    "generated = generate_seq(model, tokenizer, seq_length, prepare_txt(seed_text), 100)\n",
    "display_txt(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use custom input as seed text\n",
    "seed_text = \"Heart hammering, harry pushed his cart after them. They stopped and so did he, just near enough to hear what they were saying. Now what's the platform number? said the boy's mother. Nine and three-quarters! piped a smal girl, also red-headed, who was holding her hand, Mom, can't I go... You're not old enough Ginny now be quiet. All right Percy you go\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To the hospital wing. Harry and ron looked at the wall. Howre they doing. Asked umbridge reddening at harry with vampires cast with interest. Oh yeah you havent noticed you know who said ron clapping a hand to look at him and beckoned harry roughly. Harry looked around. The door opened. Harry yelled. It was like fangs harrys hair and bloodshot face echoed loudly with a rush of fury. Harry and ron had a very good teacher who had been a relief for being a second later he said i dunno\n"
     ]
    }
   ],
   "source": [
    "generated = generate_seq(model, tokenizer, seq_length, prepare_txt(seed_text), 100)\n",
    "display_txt(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Back. Harry asked harry grabbing note to hermione. You dont worry about me said hagrid earnestly. I suppose so said a witch and the minister of magic information yaxley is not insulting to students. I shall admit you are the caretaker. Oh yeah said mr weasley turning to the door with glee. Yep said stan indicating a slytherin quidditch squad and madame maxime and seamus finnigan fleur thomas eagerly cheered in surprise and tugged mustache whether it was a bit dangerous. The class was now shining with apprehension that floated to a large\n"
     ]
    }
   ],
   "source": [
    "generated = generate_seq(model, tokenizer, seq_length, prepare_txt(seed_text), 100)\n",
    "display_txt(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
